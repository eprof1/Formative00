{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Formative00 Part 4 \u2014 System Check\n\nRun **Run \u2192 Run All Cells**.\n\n## What this notebook checks\n- Your Python environment is working (imports + versions)\n- Optional: your laptop can reach **Local Ollama** (`http://localhost:11434`)\n- Required: you can test a **Campus LLM endpoint** (you will paste the base URL)\n- Required: you can test **Cloud OpenAI via the local proxy** (`http://localhost:8001/chat`)\n\nIf you see errors, screenshot them for your OneNote artifact.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, platform\n",
        "print('Python:', sys.version.split()[0])\n",
        "print('Platform:', platform.platform())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "import requests\n",
        "print('pandas:', pd.__version__)\n",
        "print('matplotlib:', matplotlib.__version__)\n",
        "print('requests:', requests.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Local Ollama test (laptop)\nThis may fail if Ollama is not installed/running yet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "try:\n",
        "    r = requests.get('http://localhost:11434/api/tags', timeout=3)\n",
        "    print('Ollama reachable:', r.status_code)\n",
        "    if r.ok:\n",
        "        data = r.json()\n",
        "        print('Models found:', [m['name'] for m in data.get('models', [])][:10])\n",
        "except Exception as e:\n",
        "    print('Ollama not reachable yet:', type(e).__name__, e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Campus endpoint test (required)\n\nPaste the campus base URL in the cell below.\nUse the format: `http://10.x.x.x:11434/v1`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Paste the campus base URL provided in class\n",
        "CAMPUS_BASE_URL = \"http://10.0.0.10:11434/v1\"  # change this\n",
        "\n",
        "import requests, json\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"llama3.2:1b\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Reply with exactly: CAMPUS_OK\"}],\n",
        "    \"temperature\": 0.0,\n",
        "}\n",
        "\n",
        "try:\n",
        "    r = requests.post(f\"{CAMPUS_BASE_URL}/chat/completions\", json=payload, timeout=10)\n",
        "    print('Campus status:', r.status_code)\n",
        "    data = r.json()\n",
        "    text = (data.get('choices') or [{}])[0].get('message', {}).get('content', '')\n",
        "    print('Campus response:', text)\n",
        "except Exception as e:\n",
        "    print('Campus test failed:', type(e).__name__, e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Cloud OpenAI test via local proxy (required)\n\nThis notebook does **not** call OpenAI directly.\nIt calls your **local proxy** at `http://localhost:8001/chat`.\n\nBefore running this cell, you must:\n1) Set your key in PowerShell: `$env:OPENAI_API_KEY = \"...\"`\n2) Start the proxy in another terminal: `uvicorn llm_proxy_fastapi:app --port 8001`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "payload = {\n",
        "    \"provider\": \"openai\",\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"prompt\": \"Reply with exactly: CLOUD_OK\"\n",
        "}\n",
        "\n",
        "try:\n",
        "    r = requests.post('http://localhost:8001/chat', json=payload, timeout=20)\n",
        "    print('Proxy status:', r.status_code)\n",
        "    data = r.json()\n",
        "    print('Cloud via proxy response:', data.get('text',''))\n",
        "except Exception as e:\n",
        "    print('Cloud via proxy test failed:', type(e).__name__, e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final check\nIf you reached the campus endpoint and the cloud proxy successfully, you are ready for Part 4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\u2705 System check completed')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "WSU MIS Base (wsu_mis_base)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}